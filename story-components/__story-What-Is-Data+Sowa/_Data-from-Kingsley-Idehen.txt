
source:
http://kidehen.blogspot.com/2015/07/situation-analysis-never-day-goes-by.html?view=timeslide

What is Data?
Data is how we express Observation (what we experience) in reusable form.

Actual data representation ultimately takes the form of entity relationships, inscribed to documents using a variety of notations, and then persisted using a variety of serialization formats.

Data is represented using a language — a system of signs, syntax, and semantics for encoding and decoding information (data in some context), using sentences/statements/"datums". Each sentence/statement/datum represents a singular observation.

(Some entertaining but distracting digressions — into whether the English singular datum is properly pluralized as datums or data, as datum's Latin origin might suggest; and whether the English data is a "mass noun" in its own right — are left for another day.)

Now that we have the basic unit of data expression in place — i.e., the sentence — further decomposition reveals key components such as the subject, predicate, and object (i.e., "parts of speech"; also known as the entity, attribute, and value, or the subject, verb, and object).

Sentence Construction

To create a sentence, you must have a sign ("identifier" or "signifier") mechanism for denoting the subject, predicate, and object of that sentence. Ideally, signs should function like names (i.e., be interpretable by way of lookup or "de-reference").

With signs in place, sentences need to be arranged in some systematic order (e.g., subject -> predicate -> object), according to the rules (or grammar) of a given language.

With signs and grammatical arrangement in place, the semantics (or meaning) of the subject, predicate, and object roles in a sentence need to be understood. For instance, the subject role is for the focal point entity in a relationship that possesses some discernible characteristic (or attribute). The predicate role is for the characteristic (attribute) name. The object role is for the characteristic (attribute) value.

Each of the roles above collectively impact comprehension of the nature of a relationship type (a relation) and its membership (collections of sentences that represent entities related in a specific way, determined by relationship type).

Properties of Relationship Types

Two or more entities can be related (connected) in a variety of ways, and the nature of said relationship types (relations) could be reflexive, symmetric, and/or transitive, among others. [2][3]
Simple examples

    A "knows" relationship type is defined as one that can only have a Person as the subject and another Person as the object.
    An "employed by" relationship type is defined as one that can only have a Person as the subject and an Organization as the object.
    A "mother of" relationship type is defined as one that can only have a Female Person as the subject and a Person as the object.

Data and Semantics Challenge?

The real challenge are as follows:

    Open Standards for digital sentence representation — e.g., the RDF Language from the W3C (a retrospective standardization of what was already baked into Architecture of the World Wide Web [4])

    Open Standards for signs that function like names — e.g., HTTP [5] URIs (hyperlinks) from IETF [6]

    Open Standards for machine-comprehensible representation of relationship type semantics — e.g., RDF Schema and OWL. These are collections of RDF statements (packaged as a vocabulary or ontology) that describe the nature of different entity relationship types, in machine-comprehensible form.

    Open Standards-based Query Language for interacting with relations represented as fine-grained sentence/statement graphs, rather than as coarse-grained records in a table

    Database Management Systems that can manage data represented as sentence/statement graphs, using the open standards above, without compromising access, performance, scalability, or security.


Conclusion

What we know as Data lies at the root of Language and is effectively mankind's most powerful tool. Our real challenge still lies in getting computers to augment our existing ability to communicate via sentences and statements. Pulling this off is much easier than is commonly assumed — the use of very basic sentences (at the level of a three-year-old) would escalate the power of computing and overall human productivity to unimaginable levels, as already demonstrated by what's happened thus far on the World Wide Web, where we have plenty of words, but no implicit sense of whether these are nouns, verbs, or adjectives, never mind whether they form sentences.

"Big Data" is currently understood to mean, roughly, "we have lots of books containing lots of sentences, written by many authors in a variety of notations, printed in a variety of formats, which are well beyond the storage capacity of a single library" — or "we have lots of files containing lots of statements, written by many observers in a variety of styles, saved in a variety of formats, which are well beyond the storage capacity of a single DBMS."

Conflating SQL and RDBMS is akin to claiming that sentences in books can only be presented as tables comprised of rows and columns.

"NoSQL" is an attempt to repudiate the aforementioned conflation of SQL and RDBMS, but it doesn't emphatically hone into the notion of a sentence as the mechanism for representing entity relationships, nor the nature of entity relationship types. Instead, we've wound up with "Graph" which is just another confusing term.

Ultimately, the semantics of relations are what matter. These semantics are how we encode and decode information, enabling us to put data in perceptive context, en route to creating knowledge by putting that same data into cognitive context. 



Resources:
https://www.slideshare.net/kidehen/understanding-29894555

https://en.wikipedia.org/wiki/Binary_relation

https://www.w3.org/TR/webarch/

http://kidehen.blogspot.com/2014/01/demonstrating-reasoning-via-sparql.html

